receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
      grpc:
        endpoint: 0.0.0.0:4317
processors:
  # https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/connector/servicegraphconnector/README.md
  # https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/processor/servicegraphprocessor
  tail_sampling:
    decision_wait: 10s
    num_traces: 100
    expected_new_traces_per_sec: 10
    policies:
      [
        {
          name: high-latency,
          type: latency,
          latency: { threshold_ms: 500 }
        },
        {
          name: http_error_only,
          type: numeric_attribute,
          numeric_attribute: { key: http.status_code, min_value: 500, max_value: 599 }
        }
      ]
  batch:
  batch/2:
    send_batch_size: 10000
    timeout: 10s
  resource:
    attributes:
      - key: cloud.availability_zone
        value: "zone-1"
        action: upsert # insert if not exists, update otherwise
      - key: k8s.cluster.name
        from_attribute: k8s-cluster
        action: insert # insert if not exists, do nothing otherwise
      - key: redundant-attribute
        action: delete # delete if exists
exporters:
  logging:
    loglevel: debug
  debug:
  prometheus:
    endpoint: "0.0.0.0:8889"
    send_timestamps: true
    namespace: otel
    const_labels:
      via: collector
  otlp/jaeger:
    endpoint: jaeger:4317
    tls:
      insecure: true
  zipkin:
    endpoint: "http://zipkin:9411/api/v2/spans"
    format: proto
    tls:
      insecure: true
extensions:
  health_check:
  pprof:
  zpages:
service:
  extensions: [health_check, pprof, zpages]
  telemetry:
    logs:
        level: "debug"
  pipelines:
    traces:
      receivers: [otlp]
      processors: [tail_sampling, batch, resource]
      exporters: [debug, otlp/jaeger, zipkin]
    metrics:
      receivers: [otlp]
      processors: [batch/2]
      exporters: [debug, prometheus]
